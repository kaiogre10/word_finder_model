## Resumen del modelo Word Finder

Sistema de búsqueda vectorizada basado en n-gramas para identificar campos específicos (p. ej., RFC, IVA, Total) en textos provenientes de polígonos de OCR. Combina un vectorizador TF-IDF entrenado previamente con un motor de similitud coseno para detectar variantes de etiquetas y tolerar errores comunes de OCR.

---

### 1. Arquitectura general

- Tipo de modelo: Búsqueda semántica ligera con TF-IDF + similitud coseno
- Objetivo: Encontrar campos clave (Total, IVA, RFC, etc.) en textos de polígonos OCR
- Entrenamiento: Pre-procesamiento único a partir de una base de variantes configurable (YAML)
- Persistencia: Modelo serializado (pickle) para cargas rápidas en producción

---

### 2. Estructura del proyecto

word_finder_model/
├── data/
│   ├── config.yaml                 # Configuración: campos objetivo y variantes
│   ├── word_finder_model.pkl       # Modelo TF-IDF entrenado (persistido)
│   └── logs/                       # Carpeta de logs (se crea en ejecución)
├── doc/
│   └── documentación.txt           # Este documento
├── scripts/
│   ├── generate_model.py           # Generador/entrenador del modelo
│   └── density_encoder.py          # Utilidad avanzada (soporte/experimentos)
├── src/
│   └── word_finder.py              # Lógica de búsqueda en producción
├── test/
│   ├── test_model.py               # Pruebas principales del modelo
│   ├── check_model.py              # Chequeos adicionales
│   ├── check_pickle.py             # Validación de serialización/carga
│   └── statistic.py                # Métricas y estadísticas
└── main.py                         # Punto de entrada para generar/actualizar el modelo

Notas:
- La carpeta data/logs/ se crea automáticamente en tiempo de ejecución para el registro rotativo de eventos.
- El archivo de configuración (config.yaml) es la fuente de verdad de los campos y sus variantes.

---

### 3. Componentes

A) Base de datos de palabras (YAML)
- Campos objetivo: Total, IVA, RFC, Folio, Subtotal, Descuento, etc.
- Variantes: Ejemplos “Total”, “TOTAL”, “Total:”, “Total a pagar”, “Importe total”
- Parámetros: Rango de n-gramas, umbral de similitud, y otras opciones ajustables

B) Modelo vectorizado (Pickle)
- Vectorizador TF-IDF entrenado con todas las variantes de etiquetas
- N-gramas: típicamente de 1 a 3 (unigramas, bigramas y trigramas)
- Espacio vectorial consistente, para comparar nuevos textos de forma directa

C) Motor de búsqueda
- Entrada: Texto de un polígono OCR
- Proceso: Limpieza → Vectorización → Cálculo de similitud coseno contra el espacio vectorial del modelo
- Salida: Lista de candidatos con el campo probable, la variante matcheada y un score de confianza

---

### 4. Flujo de trabajo

Fase de preparación (cuando cambie la configuración o las variantes):
1) Editar data/config.yaml con nuevos campos/variantes.
2) Generar/actualizar el modelo:
   - Opción A (recomendada): ejecutar `python main.py`
   - Opción B: ejecutar el script directamente desde scripts/generate_model.py si el proceso lo requiere.
3) Verificar que se haya creado/actualizado data/word_finder_model.pkl y revisar logs.

Fase de uso (producción):
1) Cargar una sola vez el modelo serializado en el ciclo de vida del proceso.
2) Por cada polígono OCR, vectorizar el texto y comparar su similitud con el espacio del modelo.
3) Devolver los campos identificados con su score para el pipeline posterior.

Registro (logging):
- Nivel configurable por la variable de entorno LOG_LEVEL (INFO por defecto).
- Salida a consola y a archivo rotativo en data/logs/app.txt.

---

### 5. Dependencias y entorno

- Lenguaje: Python 3.12
- Librerías clave:
  - scikit-learn (vectorización TF-IDF y similitud)
  - numpy, scipy (cálculo numérico)
  - pyyaml (lectura de configuración)
  - logging estándar de Python (registro de eventos)
- No requiere servicios externos en tiempo de ejecución.

---

### 6. Parámetros y configuración técnica

- Vectorización:
- Normalización y tokenización estándar, compatible con UTF-8
- Umbral de similitud (recomendado): ~0.75 (ajustable según el balance precisión/recobrado)
- Estructura del resultado: Por cada coincidencia se retorna el nombre del campo, la variante encontrada, el score y el texto original del polígono.

Ejemplo de salida:
[
  {
    "campo": "total",
    "palabra_encontrada": "Total:",
    "similitud": 0.95,
    "texto_original": "Total: $150.50"
  }
]

---

### 7. Ventajas del enfoque

Eficiencia
- Carga única del modelo y vectorización rápida en consulta
- Escalable para procesar grandes volúmenes de polígonos OCR

Flexibilidad
- Fácil incorporación de nuevos campos y variantes editando config.yaml
- Tolerante a errores de OCR y diferencias de formato (“Total”, “TOTAL”, “Total a pagar”)

Robustez
- Umbral de similitud ajustable para reducir falsos positivos
- Funcionamiento por polígono para mantener contexto local

---

### 8. Casos de uso

- Tickets: Total, IVA, Folio
- Facturas: RFC, Subtotal, Impuestos, Fecha
- Recibos: Cliente, Vendedor, Dirección
- Cualquier documento cuyos campos estén definidos en config.yaml

Variaciones manejadas
- Diferentes formatos: “Total:”, “Total $”, “Total a pagar”
- Diferentes mayúsculas/minúsculas: “TOTAL”, “total”, “Total”
- Errores OCR comunes: p. ej. “Tota1” ≈ “Total” si la similitud es suficiente

---

### 9. Integración en pipelines OCR

- Entrada: Texto por polígono ya extraído por tu OCR.
- Proceso: Pasar el texto del polígono al componente de búsqueda para obtener candidatos de campo.
- Salida: Campos identificados y sus scores, listos para validaciones/reglas posteriores del pipeline.

Notas de integración:
- El modelo se carga una sola vez al inicializar el proceso/worker.
- No requiere modificar la arquitectura existente: se inserta como paso de enriquecimiento.

---

### 10. Ejecución y operación

Generación/actualización del modelo:
- Comando recomendado:
  - `python main.py`
- Esto:
  - Lee data/config.yaml
  - Genera/actualiza data/word_finder_model.pkl
  - Escribe logs en data/logs/app.txt (rotativos)

Producción:
- Cargar el pickle del modelo al iniciar el servicio.
- Exponer una función/método que reciba el texto de un polígono y devuelva:
  - Campo candidato
  - Variante matcheada
  - Score de similitud
  - Texto original

Monitoreo:
- Ajustar LOG_LEVEL si se requiere más/menos verbosidad (DEBUG/INFO/WARN/ERROR).

---

### 11. Pruebas y validación

- test/test_model.py: pruebas principales para validar la calidad del modelo.
- test/check_pickle.py: asegura que la serialización/carga del modelo funcione correctamente.
- test/check_model.py y test/statistic.py: utilidades de chequeo y métricas para diagnósticos.

Sugerencias:
- Añadir casos de prueba al incorporar nuevos campos o variantes.
- Monitorear la distribución de scores y revisar umbrales periódicamente.

---

### 12. Mantenimiento y buenas prácticas

- Mantener config.yaml como única fuente de verdad de campos/variantes.
- Versionar cambios del YAML y del pickle generado.
- Revisar periódicamente el umbral de similitud según datos reales.
- Agregar variantes típicas observadas en producción para mejorar recall sin sacrificar precisión.
- Registrar ejemplos de falsos positivos/negativos para alimentar iteraciones del YAML.

---

¿Necesitas que agregue una guía breve de “cómo extender con nuevos campos” o un ejemplo de configuración YAML comentado?
